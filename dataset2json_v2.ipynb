{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create INCAR and INVICON MOLA JSON\n",
    "version: 1\n",
    "\n",
    "info:\n",
    "- Create standard MOLA JSON\n",
    "\n",
    "author: nuno costa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOLA Annotations Data Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to combine multiple datasets, it is often useful to convert them into a unified data format. \n",
    "\n",
    "Conventions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    " #ANNOTATIONS FORMAT (BASED ON COCO)\n",
    "\n",
    " #Annotations format keys:\n",
    "\n",
    "{ \"info\": None, \n",
    "\"licenses\": [], #TODO\n",
    "\"categories\": [], #NOT ZERO-PADDED (from 1 to n) WARNING: Labelling in most algorithms is zero padded , be careful \n",
    "\"images\": [],\n",
    "\"annotations\": [],\n",
    "\"videos\": [], \n",
    "\"video_annotations\": [], #TODO\n",
    "\"tracks\": [], #TODO - only for Object Tracking\n",
    "\"segment_info\": [], #TODO\n",
    "\"datasets\": [{'name': 'INCAR', 'id': 1}, {'name': 'INVICON', 'id': 2}] #NOT ZERO-PADDED (from 1 to n) \n",
    "}\n",
    "\n",
    "#IMPORTANT: CONVENTION, no zero-padding, you need to implement the zero padding afterwards (most algorithms like yolo and mmaction2 need zero-padding)\n",
    "\n",
    "#1 object definition:\n",
    "\n",
    "info: {\n",
    " \"year\": int, \n",
    " \"version\": str, \n",
    " \"description\": str, \n",
    " \"contributor\": str, \n",
    " \"url\": str, \n",
    " \"date_created\": datetime,\n",
    "}\n",
    "\n",
    "license: {\n",
    " \"id\": int, \n",
    " \"name\": str, \n",
    " \"url\": str,\n",
    "}\n",
    "\n",
    "category: {\n",
    " \"id\": int, \n",
    " \"name\": str, \n",
    " \"supercategory\": str,\n",
    " \"dataset\": int, #dataset_id\n",
    "}\n",
    "\n",
    "image: {\n",
    " \"id\" : int,\n",
    " \"video_id\": int, \n",
    " \"file_name\" : str,\n",
    " \"license\" : int,\n",
    " \"dataset\": int, #dataset_id\n",
    " # Redundant fields for COCO-compatibility\n",
    " \"width\": int,\n",
    " \"height\": int,\n",
    " \"frame_index\": int, #frame index from original video_id\n",
    " \"date_captured\": datetime,\n",
    "}\n",
    "\n",
    "annotation: { #rawframes annotation\n",
    " \"category_id\": int\n",
    " \"image_id\": int,\n",
    " #\"track_id\": int, # NOT FOR ACTION, ONLY FOR OBJECT TRACKING\n",
    " \"bbox\": [x,y,width,height],\n",
    " \"area\": float,\n",
    " \"dataset\": int, #dataset_id\n",
    " # Redundant field for compatibility with COCO scripts\n",
    " \"id\": int,\n",
    " \"iscrowd\": 0 or 1,  (iscrowd=1) are used to label large groups of objects (e.g. a crowd of people)\n",
    " \"segmentation\": RLE(iscrowd=1) or [polygon](iscrowd=0), \n",
    "\n",
    "}\n",
    "\n",
    "video: { \n",
    " \"id\": int,\n",
    " \"name\": str,\n",
    " \"width\" : int,\n",
    " \"height\" : int,\n",
    " \"total_frames\": int, # TOTAL NUMBER OF FRAMES OF THE VIDEO\n",
    " \"fps\": int,\n",
    " \"dataset\": int, #dataset_id\n",
    " #\"metadata\": dict,  # Metadata about the video - NOT NECESSARY ADDITIONAL DICT\n",
    "}\n",
    "\n",
    "video_annotation: { #TODO\n",
    " \"id\": int,\n",
    " \"category_id\": int, #label\n",
    " \"video_id\": int,\n",
    " \"frame_start\": int, #in frames, then it can be converted using the fps\n",
    " \"frame_end\":int, #in frames\n",
    " \"label_frames\": int, # TOTAL NUMBER OF FRAMES OF LABEL category_id\n",
    " \"dataset\": int, #dataset_id\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "segment: { #TODO\n",
    " \"id\": int, \n",
    " \"category_id\": int, \n",
    " \"area\": int, \n",
    " \"bbox\": [x,y,width,height], \n",
    " # Redundant field for compatibility with COCO scripts\n",
    " \"iscrowd\": 0 or 1,\n",
    "}\n",
    "\n",
    "\n",
    "track: { #DOES IT MAKE SENSE TO TRACT ACTIONS INSIDE THE VIDEO? NO- ONLY OBJECTS\n",
    " \"id\": int,\n",
    " \"category_id\": int,\n",
    " \"video_id\": int\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotate_v5 import *\n",
    "import platform \n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define root dir dependent on OS\n",
    "rdir='D:/external_datasets/MOLA/' #WARNING needs to be root datasets \n",
    "print('OS: {}'.format(platform.platform()))\n",
    "if str(platform.platform()).upper().find('linux'.upper())>-1: rdir=\"/mnt/Data-Ext/Datasets/Internal Datasets/EASYRIDE/P19/\" #'/mnt/d/external_datasets/'\n",
    "print('root dir: {}'.format(rdir))\n",
    "print('OS separator: {}'.format(os.path.sep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINGLE CASE STUDY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INIT motionLAB JSON\n",
    "- uses annotate.init_json() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res={\n",
    "    'rgb': [2048, 1536], #w,h\n",
    "    'thermal': [640,512],\n",
    "    'pointcloud': [640,576],\n",
    "    'fps': 30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_json(file='mola.json'):\n",
    "    output = {\n",
    "        \"info\": None,\n",
    "        \"licenses\": [],\n",
    "        \"categories\": [],\n",
    "        \"videos\": [],\n",
    "        \"images\": [],\n",
    "        \"tracks\": [],\n",
    "        \"segment_info\": [],\n",
    "        \"annotations\": [],\n",
    "        \"video_annotations\": [],\n",
    "        \"datasets\": [] #[{'name': 'COCO', 'id': 1}, {'name': 'TAO', 'id': 2}] #Not zero-padded\n",
    "    }\n",
    "    output['info'] = {\n",
    "        \"description\": \"MOLA Dataset\",\n",
    "        \"url\": \"\",\n",
    "        \"version\": \"1\",\n",
    "        \"year\": 2021,\n",
    "        \"date_created\": datetime.datetime.utcnow().isoformat(' ')\n",
    "    }\n",
    "\n",
    "    with open(file, 'w') as f:\n",
    "        json.dump(output, f)\n",
    "    print(\"JSON INITIATED : {}\".format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molafile=rdir+'INCAR/'+'mola.json'\n",
    "init_json(file=molafile)\n",
    "molajson =  json.load(open(molafile))\n",
    "molajson['datasets']=[{'name': 'INCAR', 'id': 1}]\n",
    "with open(molafile, 'w') as f:\n",
    "    json.dump(molajson, f)\n",
    "for k in molajson:\n",
    "    print(k, len(molajson[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT JSON LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=rdir+\"INCAR/20210506/Session 1/C8_P6_P5_1/gt.json\"\n",
    "gt=json.load(open(file))\n",
    "mergedjson = json.load(open(rdir+'/annotations/splitann_mola_fix_equal_reorder_cleanclass_cleanimg/mix_coco_and_tao_aggressive/test.json')) #EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_path(path):\n",
    "    parsed_path = path.replace('\\\\', '/')\n",
    "    parsed_path = parsed_path.replace('\\ ', '/')\n",
    "    return parsed_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_pahts(gt, remove_gt=True, dataset_root=\"INCAR\", replace_sensor=[\"nvs_push\", \"rgb\"]):\n",
    "    \"\"\"\n",
    "    replace_sensor=[\"nvs_push\", \"rgb\"] or NONE to not replace\n",
    "    \"\"\"\n",
    "    #fix gt datasource\n",
    "    paths=gt['gTruth2']['DataSource']\n",
    "    if isinstance(paths, dict) and 'Source' in paths: paths=paths['Source']\n",
    "    paths=[parse_path(p) for p in paths]\n",
    "    #remove MATLAB BUG: 'C:\\\\Tools\\\\MATLAB\\\\R2020a\\\\examples\\\\symbolic\\\\data\\\\196.png'\n",
    "    originalpath=paths[0]\n",
    "    for p in paths: #verify it is not a matlab path the first one\n",
    "        if not p.find(\"MATLAB\") >-1 : \n",
    "            originalpath=p\n",
    "            break\n",
    "    originalpath=parse_path(originalpath) \n",
    "    paths = ['/'.join(originalpath.split('/')[:-1]+[p.split('/')[-1]]) if p.find(\"MATLAB\") > -1 else p for p in paths]  \n",
    "    #remove root dir \n",
    "    paths = ['/'.join(p.split('/')[p.split('/').index(dataset_root):]) for p in paths] \n",
    "    #remove gt dir\n",
    "    if remove_gt: paths = [p.replace(\"/gt/\",\"/\") if p.find('/gt/')>-1 else p for p in paths]\n",
    "    if replace_sensor:\n",
    "        paths = [p.replace(replace_sensor[0], replace_sensor[1])for p in paths] \n",
    "    gt['gTruth2']['DataSource']=paths\n",
    "    return gt\n",
    "gt=fix_pahts(gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CATEGORIES IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXAMPLE\n",
    "#display(mergedjson[\"categories\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gt['gTruth']['LabelDefinitions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_categories(molajson, gt, start_id=0):\n",
    "    dataset=molajson[\"datasets\"][0]['id']\n",
    "    # IMPORT categories name and id\n",
    "    cat_l=[]\n",
    "    cat_l_id=[]\n",
    "    cat_l_dset=[]\n",
    "    cat=gt['gTruth']['LabelDefinitions']\n",
    "    for i,c in enumerate(tqdm(cat)):\n",
    "        cat_l.append(c['Name'])\n",
    "        cat_l_id.append(start_id+i+1) # id start from 1\n",
    "        cat_l_dset.append(dataset) # dataset index\n",
    "        molajson['categories'].append({'name':cat_l[i],'id':cat_l_id[i],'dataset':cat_l_dset[i]})\n",
    "    # ADDITIONAL CATEGORIES: MANUAL\n",
    "    name='NONVIOLENT'\n",
    "    cid=len(cat_l)+1\n",
    "    molajson['categories'].append({'name':name,'id':cid,'dataset':dataset})\n",
    "    cat_l.append(name)\n",
    "    cat_l_id.append(cid)\n",
    "    cat_l_dset.append(dataset)\n",
    "    print(\"\\n>> categories:\\n\", molajson['categories'][-2:])\n",
    "    return molajson, cat_l, cat_l_id, cat_l_dset\n",
    "#molajson, cat_l, cat_l_id, cat_l_dset=import_categories(molajson, gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VIDEO IMPORT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def import_videos(molajson, gt, res, start_id=0, sensor=\"rgb\", ext=\".mp4\"):\n",
    "    dataset=molajson[\"datasets\"][0]['id']\n",
    "    #single-level:\n",
    "    vid=start_id+1\n",
    "    video_l=[]\n",
    "    video_l_id=[]\n",
    "    total_frames=len(gt['gTruth']['DataSource'])\n",
    "    #INCAR/20210521/Session 2/C9_P4_P3_2/rgb\n",
    "    videon='_'.join(gt['gTruth']['DataSource'][0].split('/')[:4])+'_'+sensor+ext #f'video_{vid}_{sensor}{ext}' \n",
    "    videon=videon.replace(' ','_') # remove trailing spaces in \"Session 1\"\n",
    "    video='/'.join(gt['gTruth']['DataSource'][0].split('/')[:4])+'/'+videon\n",
    "    video_l.append(video)\n",
    "    video_l_id.append(vid)\n",
    "    i=0 #no loop\n",
    "    molajson['videos'].append({'name':video_l[i],\n",
    "                               'id':video_l_id[i],\n",
    "                               'width': res[sensor][0],\n",
    "                               'height': res[sensor][1],\n",
    "                               'sensor': sensor,\n",
    "                               'fps': res['fps'],\n",
    "                               'total_frames': total_frames,\n",
    "                               'dataset':dataset})\n",
    "    print(\"\\n>> video:\\n\", molajson['videos'][-2:])\n",
    "    return molajson, video_l, video_l_id\n",
    "#molajson, video_l, video_l_id=import_videos(molajson, gt, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMAGE IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXAMPLE\n",
    "display(mergedjson[\"images\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt['gTruth']['DataSource'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_images(molajson, gt, res, start_id=0, video_id=1, sensor=\"rgb\"):\n",
    "    dataset=molajson[\"datasets\"][0]['id']\n",
    "    # images filepath and id\n",
    "    img_l=[]\n",
    "    img_l_id=[]\n",
    "    img=gt['gTruth']['DataSource']\n",
    "    for i,im in enumerate(tqdm(img)):\n",
    "        img_l.append(im)\n",
    "        img_l_id.append(start_id+i+1) # id start from 1\n",
    "        frame_index=img_l[i].split('/')[-1]\n",
    "        frame_index=int(frame_index.split('.')[0])\n",
    "        molajson['images'].append({'file_name':img_l[i],\n",
    "                                   'id':img_l_id[i],\n",
    "                                   'video_id':video_id,\n",
    "                                   'caption':img_l[i].split('/')[-4], # scenario\n",
    "                                   'width': res[sensor][0],\n",
    "                                   'height': res[sensor][1],\n",
    "                                   \"frame_index\": frame_index,\n",
    "                                   \"date_captured\": img_l[i].split('/')[-6],\n",
    "                                   'dataset':dataset})\n",
    "    print(\"\\n>> images:\\n\", molajson['images'][-2:])\n",
    "    return molajson, img_l, img_l_id\n",
    "#molajson, img_l, img_l_id=import_images(molajson, gt, res, video_id=video_l_id[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CREATE ANNOTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXAMPLE\n",
    "display(mergedjson[\"annotations\"][1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt['gTruth']['LabelData'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annotations(molajson, gt, res, cat_l, cat_l_id, cat_l_dset, img_l_id, start_id=0, sensor=\"rgb\"):\n",
    "    dataset=molajson[\"datasets\"][0]['id']\n",
    "    # annotations category_id, image_id, bbox, and dataset\n",
    "    ann_id=[]\n",
    "    ann_catid=[]\n",
    "    ann_imgid=[]\n",
    "    ann_bbox=[]\n",
    "    ann_dset=[]\n",
    "    labels=gt['gTruth']['LabelData']\n",
    "    for i,l in enumerate(tqdm(labels)):\n",
    "        annid=start_id+i+1\n",
    "        current_label=list(l.keys())[0]\n",
    "        if current_label=='VIOLENT' and not l[\"VIOLENT\"]: current_label=\"NONVIOLENT\" #specific rule of gt labelling\n",
    "        catidx=cat_l.index(current_label)\n",
    "        catid=cat_l_id[catidx]\n",
    "        imgidx=i #frame\n",
    "        imgid=img_l_id[imgidx]\n",
    "        bbox=[0, 0, res[sensor][0], res[sensor][1]] # [x,y,width,height], #default RGB\n",
    "        area=res[sensor][0]*res[sensor][1] #default RGB\n",
    "        ann_id.append(annid)\n",
    "        ann_catid.append(catid)\n",
    "        ann_imgid.append(imgid)\n",
    "        ann_bbox.append(bbox)\n",
    "        ann_dset.append(dataset)\n",
    "        molajson['annotations'].append({'id':annid,\n",
    "                                        'category_id':catid,\n",
    "                                        'image_id':imgid,\n",
    "                                        'bbox': bbox,\n",
    "                                        'area': area,\n",
    "                                        'iscrowd': 0,\n",
    "                                        'dataset':dataset})\n",
    "    print(\"\\n>> annotations:\\n\", molajson['annotations'][-2:])\n",
    "    return molajson, ann_id, ann_catid, ann_imgid, ann_bbox, ann_dset\n",
    "#molajson, ann_id, ann_catid, ann_imgid, ann_bbox, ann_dset=create_annotations(molajson, gt,res, cat_l, cat_l_id, cat_l_dset, img_l_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n>> annotations:\\n\", molajson['annotations'][-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_annotations(molajson, gt, res, cat_l, cat_l_id, cat_l_dset, video_l_id, start_id=0, sensor=\"rgb\"):\n",
    "    dataset=molajson[\"datasets\"][0]['id']\n",
    "    # annotations category_id, image_id, bbox, and dataset\n",
    "    ann_id=[]\n",
    "    ann_catid=[]\n",
    "    ann_videoid=[]\n",
    "    ann_dset=[]\n",
    "    labels=gt['gTruth']['LabelData']\n",
    "    #extract frames and correspondent labels\n",
    "    labels_l=[]\n",
    "    frames_l=[]\n",
    "    previous_label=''\n",
    "    frames_per_label=[]\n",
    "    for i,l in enumerate(labels): #UNSPECIFIC LABEL EXTRACTOR\n",
    "        current_label=list(l.keys())[0]\n",
    "        if current_label=='VIOLENT' and not l[\"VIOLENT\"]: current_label=\"NONVIOLENT\" #specific rule of gt labelling\n",
    "        if previous_label != current_label or i+1>=len(labels):\n",
    "            if i+1>=len(labels): frames_per_label.append(i+1)\n",
    "            if frames_per_label: frames_l.append(frames_per_label)\n",
    "            if previous_label !='': labels_l.append(previous_label)\n",
    "            previous_label=current_label\n",
    "            frames_per_label=[]\n",
    "        frames_per_label.append(i+1)\n",
    "    #create video annotations\n",
    "    for i,c in enumerate(labels_l):\n",
    "        annid=start_id+i+1\n",
    "        catidx=cat_l.index(c)\n",
    "        label_frames=frames_l[i]\n",
    "        if not label_frames: continue #no frames\n",
    "        catid=cat_l_id[catidx] \n",
    "        videoidx=0 #only one video per scenario\n",
    "        videoid=video_l_id[videoidx]\n",
    "        ann_id.append(annid)\n",
    "        ann_catid.append(catid)\n",
    "        ann_videoid.append(videoid)\n",
    "        ann_dset.append(dataset)\n",
    "        molajson['video_annotations'].append({'id':annid,\n",
    "                                        'category_id':catid,\n",
    "                                        'video_id':videoid,\n",
    "                                        'frame_start': int(label_frames[0]), #in frames, then it can be converted using the fps\n",
    "                                        'frame_end': int(label_frames[-1]), #in frames\n",
    "                                        \"label_frames\": len(label_frames),\n",
    "                                        'dataset':dataset})\n",
    "    print(\"\\n>> video_annotations:\\n\", molajson['video_annotations'][-2:])\n",
    "    \"\"\"  \n",
    "    frames_violent=[i+1 for i,l in enumerate(labels) if l[\"VIOLENT\"]]\n",
    "    frames_nonviolent=[i+1 for i,l in enumerate(labels) if not l[\"VIOLENT\"]]\n",
    "    for i,c in enumerate(tqdm(cat_l)):\n",
    "        annid=start_id+i+1\n",
    "        catidx=i\n",
    "        #specific - TODO unspecific\n",
    "        label_frames=frames_violent\n",
    "        if c==\"NONVIOLENT\": label_frames=frames_nonviolent\n",
    "        if not label_frames: continue #no frames of this category, therefore video of this category\n",
    "        catid=cat_l_id[catidx]\n",
    "        #dataset=cat_l_dset[catidx]\n",
    "        videoidx=0 #only one video per scenario\n",
    "        videoid=video_l_id[videoidx]\n",
    "        ann_id.append(annid)\n",
    "        ann_catid.append(catid)\n",
    "        ann_videoid.append(videoid)\n",
    "        ann_dset.append(dataset)\n",
    "        molajson['video_annotations'].append({'id':annid,\n",
    "                                        'category_id':catid,\n",
    "                                        'video_id':videoid,\n",
    "                                        'frame_start': int(label_frames[0]), #in frames, then it can be converted using the fps\n",
    "                                        'frame_end': int(label_frames[-1]), #in frames\n",
    "                                        \"label_frames\": len(label_frames),\n",
    "                                        'dataset':dataset})\n",
    "    print(\"\\n>> video_annotations:\\n\", molajson['video_annotations'][-2:])\"\"\"\n",
    "    return molajson, ann_id, ann_catid, ann_videoid, ann_dset\n",
    "#molajson, ann_id, ann_catid, ann_videoid, ann_dset=create_video_annotations(molajson, gt,res, cat_l, cat_l_id, cat_l_dset, video_l_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missings handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def missings_handler(imgdir,sensor):\n",
    "    gt = {'gTruth': {\n",
    "        'DataSource': ['INCAR/20210521/Session 2/C9_P4_P3_2/rgb/1.png'],\n",
    "        'LabelDefinitions': [{'Name': 'VIOLENT','Type': 'Scene','LabelColor': [0, 0.7241, 0.6552],'Group': 'None','Description': ''}],\n",
    "        'LabelData': [{'VIOLENT': False}]}}\n",
    "    DIR = os.path.join(imgdir,sensor)\n",
    "    L_DIR = os.listdir(DIR)\n",
    "    L_DIR = sorted(L_DIR, key=lambda x: int(os.path.splitext(x.split('/')[-1])[0]))\n",
    "    frameslist=[name for name in L_DIR if os.path.isfile(os.path.join(DIR, name))]\n",
    "    gt['gTruth']['DataSource']=[os.path.join(DIR, frame) for frame in frameslist]\n",
    "    gt['gTruth']['LabelData']=[{'VIOLENT': False} for frame in frameslist]\n",
    "        \n",
    "    return gt\n",
    "#gt=missings_handler('/mnt/Data-Ext/Datasets/Internal Datasets/EASYRIDE/P19/INCAR/20210422/Session1/C13_P7_P8_1','rgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTI CASE STUDY (For loop script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets=[\"INVICON\"]#['INCAR', 'INVICON']\n",
    "rdir=rdir\n",
    "# FOR LOOP\"\n",
    "datasetsdir = os.listdir(rdir)\n",
    "missing_gt_json=[]\n",
    "missing_gt_mat=[]\n",
    "label_folder=\"\"#\"gt\"\n",
    "missings_handler_b=True \n",
    "label_fname=\"gt.json\"\n",
    "label_mat_fname=\"gt.m\"\n",
    "sensor=\"rgb\"\n",
    "ext=\".mp4\"\n",
    "did=1 #start dataset id\n",
    "for dataset in datasetsdir:\n",
    "    if dataset in datasets:\n",
    "        daysdir = os.path.join(rdir, dataset)\n",
    "        if not os.path.isdir(daysdir): continue  # test if is a folder\n",
    "        days = os.listdir(daysdir)\n",
    "        print(\">>>\\n EXTRACTING DATASET: \"+dataset)\n",
    "        #INIT JSON\n",
    "        molafile=rdir+dataset+'/'+'mola.json'\n",
    "        init_json(file=molafile)\n",
    "        molajson =  json.load(open(molafile))\n",
    "        molajson['datasets'] = [{'name': dataset, 'id': did}] #[{'name': d, 'id': i+1} for i,d in enumerate(datasets)]\n",
    "        did+=1 #nem dataset added\n",
    "        with open(molafile, 'w') as f:\n",
    "            json.dump(molajson, f)\n",
    "        #INIT VARS\n",
    "        imported_cats = False # import cats from each dataset\n",
    "        cat_start_id = 0\n",
    "        video_start_id = 0\n",
    "        img_start_id = 0\n",
    "        ann_start_id = 0\n",
    "        vid_ann_start_id = 0\n",
    "        cat_l, cat_l_id, cat_l_dset = [], [], []\n",
    "        video_l, video_l_id = [], []\n",
    "        img_l, img_l_id = [], []\n",
    "        ann_id, ann_catid, ann_imgid, ann_bbox, ann_dset = [], [], [], [], []\n",
    "        vid_ann_id, vid_ann_catid, ann_videoid, vid_ann_dset = [], [], [], []\n",
    "        #FOR LOOP\n",
    "        for day in days:\n",
    "            sessiondir = os.path.join(daysdir, day)\n",
    "            if not os.path.isdir(sessiondir): continue  # test if is a folder\n",
    "            sessions = os.listdir(sessiondir)\n",
    "            for session in sessions:\n",
    "                scenariosdir = os.path.join(sessiondir, session)\n",
    "                if not os.path.isdir(scenariosdir): continue  # test if is a folder\n",
    "                scenarios = os.listdir(scenariosdir)\n",
    "                for scenario in scenarios:\n",
    "                    imgdir = os.path.join(scenariosdir, scenario)\n",
    "                    if not os.path.isdir(imgdir): continue  # test if is a folder\n",
    "                    labeldir = os.path.join(imgdir, label_folder)\n",
    "                    # if not os.path.isdir(labeldir): continue #should exist\n",
    "                    filename = os.path.join(labeldir, label_fname)\n",
    "                    #TEST if sensor folder exists\n",
    "                    sensorfolder = os.path.join(labeldir, sensor)\n",
    "                    if not os.path.isdir(sensorfolder): continue \n",
    "                    try:\n",
    "                        gt = json.load(open(filename))\n",
    "                    except:\n",
    "                        if missings_handler_b:\n",
    "                            print(\"\\n\\n>>>>>>>CONVERTING MISSING  gtFILE: \", filename)\n",
    "                            try:\n",
    "                                gt = missings_handler(imgdir,sensor)\n",
    "                                gt = fix_pahts(gt, dataset_root=dataset) #gTruth can be also missing missing\n",
    "                                missing_gt_json.append([filename,\"CONVERTED\"])\n",
    "                                if not os.path.isfile(filename.replace(label_fname, label_mat_fname)): missing_gt_mat.append(filename.replace(label_fname, label_mat_fname))\n",
    "                            except Exception as e:\n",
    "                                print(\">>>>>>>MISSING: \", filename, e, sys.exc_info()[0])\n",
    "                                missing_gt_json.append([filename,\"FAIL_CONVERT\"])\n",
    "                                if not os.path.isfile(filename.replace(label_fname, label_mat_fname)): missing_gt_mat.append(filename.replace(label_fname, label_mat_fname))\n",
    "                                continue\n",
    "                        else:\n",
    "                            print(\">>>>>>>MISSING : \", filename)\n",
    "                            missing_gt_json.append([filename,\"MISSING\"])\n",
    "                            if not os.path.isfile(filename.replace(label_fname, label_mat_fname)): missing_gt_mat.append(filename.replace(label_fname, label_mat_fname))\n",
    "                            continue\n",
    "                    #Fix paths\n",
    "                    try:\n",
    "                        gt = fix_pahts(gt, dataset_root=dataset) #gTruth can be also missing missing\n",
    "                    except:\n",
    "                        print(\">>>>>>> BUG gtFILE: \", filename)\n",
    "                        missing_gt_json.append([filename,\"BUG in GT file\"])\n",
    "                        if not os.path.isfile(filename.replace(label_fname, label_mat_fname)): missing_gt_mat.append(filename.replace(label_fname, label_mat_fname))\n",
    "                        continue\n",
    "                    # update molajson\n",
    "                    if not imported_cats:  # only imports one time\n",
    "                        molajson, cat_l, cat_l_id, cat_l_dset = import_categories(molajson, gt, start_id=cat_start_id)\n",
    "                        imported_cats = True        \n",
    "                    molajson, video_l, video_l_id=import_videos(molajson, gt, res,\n",
    "                                                                start_id=video_start_id,\n",
    "                                                                sensor=sensor,\n",
    "                                                                ext=ext)\n",
    "                    molajson, img_l, img_l_id=import_images(molajson, gt, res, \n",
    "                                                            start_id=img_start_id,\n",
    "                                                            sensor=sensor,\n",
    "                                                            video_id=video_l_id[-1])\n",
    "                    molajson, ann_id, ann_catid, ann_imgid, ann_bbox, ann_dset = create_annotations(molajson, gt, res,\n",
    "                                                                                                    cat_l, cat_l_id,\n",
    "                                                                                                    cat_l_dset, img_l_id,\n",
    "                                                                                                    start_id=ann_start_id,\n",
    "                                                                                                    sensor=sensor)\n",
    "                    molajson, vid_ann_id, vid_ann_catid, ann_videoid, vid_ann_dset=create_video_annotations(molajson, gt,res, \n",
    "                                                                                                cat_l, cat_l_id, \n",
    "                                                                                                cat_l_dset, video_l_id,\n",
    "                                                                                                start_id=vid_ann_start_id,\n",
    "                                                                                                sensor=sensor)\n",
    "                    # update start ids to the last id\n",
    "                    try:                     \n",
    "                        cat_start_id = cat_l_id[-1]\n",
    "                        video_start_id = video_l_id[-1]\n",
    "                        img_start_id = img_l_id[-1]\n",
    "                        ann_start_id = ann_id[-1]\n",
    "                        vid_ann_start_id = vid_ann_id[-1]\n",
    "                    except Exception as e:\n",
    "                        print(\">>>>>>> BUG IDs: \", filename, e, sys.exc_info()[0])\n",
    "                        missing_gt_json.append([filename,\"BUG IDs, missing frames?\", e])\n",
    "                        continue\n",
    "\n",
    "\n",
    "        # results\n",
    "        for k in molajson:\n",
    "            print(k, len(molajson[k]))\n",
    "\n",
    "        # # Save\n",
    "        print('\\n >> SAVING...')\n",
    "        jsonfile=molafile\n",
    "        with open(jsonfile, 'w') as f:\n",
    "            json.dump(molajson, f)\n",
    "        with open(jsonfile.replace('.json', '_missing_gtmat.txt'),'w') as f:\n",
    "            f.write(str(missing_gt_mat))\n",
    "        with open(jsonfile.replace('.json', '_missing_gtjson.txt'),'w') as f:\n",
    "            f.write(str(missing_gt_json))\n",
    "        print(\"JSON SAVED : {} \\n\".format(jsonfile))\n",
    "\n",
    "        #retest results\n",
    "        molajson =  json.load(open(molafile))\n",
    "        for k in molajson:\n",
    "            print(k, len(molajson[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "molafile=rdir+'INCAR/'+'mola.json'\n",
    "print(molafile)\n",
    "molajson =  json.load(open(molafile))\n",
    "for k in molajson:\n",
    "    print(k, len(molajson[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molafile=rdir+'INVICON/'+'mola.json'\n",
    "molajson =  json.load(open(molafile))\n",
    "for k in molajson:\n",
    "    print(k, len(molajson[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molajson[\"datasets\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "molajson[\"categories\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "molajson[\"videos\"][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molajson[\"images\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molajson[\"images\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molajson[\"annotations\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molajson[\"annotations\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molajson[\"video_annotations\"][32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create video ann dict {video_id_category_id: video_annotations}\n",
    "videos_ann = {'%g' % x['id'] +'_'+'%g' % x['video_id'] +'_'+'%g' % x['category_id']: x for x in molajson['video_annotations']}\n",
    "k_14_2=[k for k in list(videos_ann.keys()) if k.find('_14_2')>-1]\n",
    "for k in k_14_2:\n",
    "    display(videos_ann[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
