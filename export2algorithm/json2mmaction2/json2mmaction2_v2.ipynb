{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# json2mmaction2\n",
    "version: 1\n",
    "\n",
    "info:\n",
    "- Create standard mola JSON\n",
    "\n",
    "author: nuno costa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import copy\n",
    "import glob\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folders(path='../out/'):\n",
    "    # Create folders\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)  # delete output folder\n",
    "    os.makedirs(path)  # make new output folder\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file(src,dst,copy=True):\n",
    "    extracted=True\n",
    "    try:\n",
    "        if copy: \n",
    "            if not os.path.exists(os.path.dirname(dst)): \n",
    "                os.makedirs(os.path.dirname(dst)) #make sure dir exists\n",
    "            shutil.copyfile(src, dst)  # raises if missing files\n",
    "        else: #if not copy only extracting filelist from json\n",
    "            if not os.path.exists(src): raise\n",
    "    except:\n",
    "        #print(\"\\n>> missing : {}\".format(src))\n",
    "        extracted=False\n",
    "    return extracted\n",
    "#extract_file(\"/home/administrator/server_data_ext/Recordings/EASYRIDE/P19/INCAR/20210422/Session1/C1_P7_P8_1/gt/rgb/1.png\",\"/home/administrator/Desktop/INCAR_20210427_Session_1_C10_P13_P14_1_rgb/img_1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINGLE CASE STUDY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_root_dir=\"/mnt/Data-Ext/Datasets/Internal Datasets/EASYRIDE/P19/\"\n",
    "json_dir=datasets_root_dir+\"JSONS/INCAR/violent_2c_toC20/select/\"\n",
    "outdir='/home/user/Desktop/NC/DATASETS/mma2/INCAR2c_thermal_violent/' #don't forget the last\n",
    "dataset=\"INCAR2c\"\n",
    "dataset_type='rawframes'\n",
    "filename=f'{dataset}_total_{dataset_type}.txt' #filelist total .txt name\n",
    "json_file = json_dir+'mola.json'\n",
    "img_number=None #STOP CONDITION : None copies all\n",
    "copy_images=True #if false only filelist is extracted from json\n",
    "copy_videos=False\n",
    "level=2 #level: 1- one level - ; 2-two-level - classes split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PREPARE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_from_annotation(json_file, data, images, videos, categories, videos_ann, \n",
    "                          copy_images, copy_videos, outdir_img, outdir_video, \n",
    "                          img_number=None, level=2, min_frames=30, img_format = \".png\"):\n",
    "    # WRITE FILES (COPY & GENERATE FILELIST)\n",
    "    # image lists\n",
    "    img_l = []\n",
    "    saved_img_l= []\n",
    "    imglist = []\n",
    "    img_counter = 0 # image counter\n",
    "    # video lists\n",
    "    video_l = []\n",
    "    saved_video_l= []\n",
    "    videolist = []\n",
    "    # write files \n",
    "    method=\"for\" #TODO: parfor method\n",
    "    start=time.time()\n",
    "    if method==\"for\":\n",
    "        #WRITE IMAGES\n",
    "        for x in tqdm(data['annotations'], desc='Annotations %s' % json_file):  \n",
    "            # extract label and category\n",
    "            catid = '%g' % x['category_id']\n",
    "            category = categories[catid]['name']\n",
    "            label = int(x['category_id']) - 1 #NOTE: MMACTION2 categories are zero-padded;mola JSON Annotations start by convention in 1\n",
    "            # extract image info from x['image_id']\n",
    "            image_id='%g' % x['image_id']\n",
    "            if image_id in img_l: continue # continue to next loop if repeated image_id \n",
    "            img_l.append(image_id)\n",
    "            img = images[image_id]\n",
    "            h, w, imgf = img['height'], img['width'], img['file_name']\n",
    "            _, img_ext = os.path.splitext(imgf)\n",
    "            img_fn = Path(imgf).stem\n",
    "            img_frame = img['frame_index'] \n",
    "            img_frame_original=copy.copy(img_frame)\n",
    "            # extract video info from img['video_id']\n",
    "            video_id = '%g' % img[\"video_id\"]\n",
    "            video = videos[video_id]\n",
    "            videof= video[\"name\"]\n",
    "            video_fn = Path(videof).stem\n",
    "            keys_l=[k for k in list(videos_ann.keys()) if k.find('_'+video_id+'_'+catid)>-1]\n",
    "            video_key=[k for k in keys_l if img_frame>=videos_ann[k]['frame_start'] and img_frame<=videos_ann[k]['frame_end']]\n",
    "            if not video_key: continue #IMG FRAME DOES NOT BELONG TO THIS ANNOTATION\n",
    "            if len(video_key)>1: raise AssertionError(\"Current rule - An image can only be in one annotation label!\")\n",
    "            video_key= video_key[0] #Only one \n",
    "            video_ann= videos_ann[video_key]\n",
    "            video_start_frame=video_ann[\"frame_start\"] # No zero-padding in the frames\n",
    "            video_end_frame=video_ann[\"frame_end\"] # No zero-padding \n",
    "            # extract total label frames\n",
    "            total_frames = '%g' % video_ann['label_frames']\n",
    "            if video_ann['label_frames']<30: continue\n",
    "            # extract bounding box format is [top left x, top left y, width, height] | [x,y,w,h]\n",
    "            box = np.array(x['bbox'], dtype=np.float64) \n",
    "            box[:2] += box[2:] / 2  # xy top-left corner to center\n",
    "            box[[0, 2]] /= w  # normalize x & w\n",
    "            box[[1, 3]] /= h  # normalize y & h\n",
    "            if (box[2] > 0.) and (box[3] > 0.):  # if w > 0 and imgf > 0\n",
    "                # New fnames\n",
    "                img_frame_original= img_frame_original # No zero-padding because frame starts in one\n",
    "                img_frame=str(int(img_frame_original)-int(video_start_frame) +1)# update img_frame, +1 to not have zero-padding\n",
    "                img_new_fn = \"img_\"+img_frame.zfill(5) #img_framenumber (imgid with zeros 00001: image_frame.zfill(5) ) #WARNING: Problem is I don't no the maximum of images at this point\n",
    "                video_new_fn = video_fn+'_'+'%g' % video_ann['id'] #the video annotation id is obligatory\n",
    "                # write images - 1st because if copy_images fails the rest should not be done\n",
    "                imgf = imgf.split(\".\")[0]+img_format\n",
    "                src = os.path.join(datasets_root_dir, imgf)\n",
    "                img_ext = img_format\n",
    "                dst = os.path.join(outdir_img, video_new_fn, img_new_fn + img_ext)\n",
    "                if level==2: dst = os.path.join(outdir_img, category, video_new_fn, img_new_fn + img_ext)\n",
    "                ext=extract_file(src,dst,copy=copy_images)\n",
    "                if not ext: continue #if image missing from dataset when extracting images dont write nothing more\n",
    "                # img list: \n",
    "                imgline = f'{video_new_fn}/{img_new_fn}\\n' # f'{video_new_fn}/{img_new_fn} {total_frames} {label}\\n'\n",
    "                if level==2: imgline = f'{category}/{video_new_fn}/{img_new_fn}\\n' # f'{category}/{video_new_fn}/{img_new_fn} {total_frames} {label}\\n'\n",
    "                imglist.append(imgline)\n",
    "                img_counter += 1\n",
    "                # rawframe annotation file list: json to txt [ frame_directory total_frames label  ]\n",
    "                vidline = f'{video_new_fn} {total_frames} {label}\\n'\n",
    "                if level==2: vidline = f'{category}/{video_new_fn} {total_frames} {label}\\n' \n",
    "                videolist.append(vidline)\n",
    "            # STOP conditions\n",
    "            if img_number and img_counter >= img_number: \n",
    "                print(\"STOP CONDITION\")\n",
    "                break\n",
    "        #remove duplicate paths\n",
    "        imglist=list(dict.fromkeys(imglist)) \n",
    "        videolist=list(dict.fromkeys(videolist)) \n",
    "    stop = time.time()\n",
    "    elapsed=stop-start\n",
    "    print(\"time elapsed:\", elapsed)\n",
    "    return imglist, videolist, saved_img_l, saved_video_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mola2mmaction2(datasets_root_dir=None, json_file='push_mola.json', outdir='out/', copy_images=True, copy_videos=False, img_number=None, level=2):\n",
    "    \n",
    "    # MAKE ROOT DIRS\n",
    "    make_folders(path=outdir)  # output directory\n",
    "    videodir_path = 'videos'\n",
    "    imgdir_path = 'rawframes' # (OBLIGATORY) \"rawframes\" name is used in other functions\n",
    "    outdir_video = os.path.join (outdir, videodir_path)\n",
    "    outdir_img = os.path.join (outdir, imgdir_path)\n",
    "    if copy_videos: make_folders(path=outdir_video)\n",
    "    if copy_images: make_folders(path=outdir_img)\n",
    "    # PARSE JSON ANNOTATIONS\n",
    "    data=None\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "    if not data: raise\n",
    "    # create image dict {id: image}\n",
    "    images = {'%g' % x['id']: x for x in data['images']}\n",
    "    # create video dict {id: video}\n",
    "    videos = {'%g' % x['id']: x for x in data['videos']}\n",
    "    # create category dict {id: category}\n",
    "    categories = {'%g' % x['id']: x for x in data['categories']}\n",
    "    # create video ann dict {video_id_category_id: video_annotations}\n",
    "    videos_ann = {'%g' % x['id'] +'_'+'%g' % x['video_id'] +'_'+'%g' % x['category_id']: x for x in data['video_annotations']}\n",
    "    # WRITE FILES (COPY & GENERATE FILELIST)\n",
    "    method=\"from_annotation\"\n",
    "    if method==\"from_annotation\": \n",
    "        imglist, videolist, saved_img_l, saved_video_l=write_from_annotation(json_file, data, images, videos, categories, videos_ann, copy_images, copy_videos, outdir_img, outdir_video, img_number=img_number, level=level)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return imglist, videolist, saved_img_l, saved_video_l\n",
    "#imglist, videolist, saved_img_l, saved_video_l = mola2mmaction2(datasets_root_dir=datasets_root_dir, json_file=json_file, outdir=outdir, copy_images=copy_images, copy_videos=copy_videos, img_number=img_number, level=level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE FILELIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RENAME FRAMES FILEPATHS (OBLIGATORY: mmaction2 can have errors if the total frame number is not equal to the number on filename or there are jumps in numbering)\n",
    "def rename_filepaths_from_dir(path, img_format = \".png\"):\n",
    "    #because of possible missing files or miss placement of total frames\n",
    "    for subdir, dirs, files in tqdm(os.walk(path)):\n",
    "        print(subdir)\n",
    "        #print(dirs)\n",
    "        print(len(files))\n",
    "        files.sort()\n",
    "        for i,file in enumerate(files):\n",
    "            if file.endswith(img_format):\n",
    "                newfile=\"img_\"+str(i+1).zfill(5)+ img_format\n",
    "                if file==newfile: continue\n",
    "                src = os.path.join(subdir,file)\n",
    "                dst = os.path.join(subdir,\"rename_\"+newfile) #rename_ is necessary for not substituing previous file\n",
    "                try:\n",
    "                    os.rename(src,dst)\n",
    "                    #print(\"\\n>> rename success: from {} to {}\".format(file,newfile))\n",
    "                except:\n",
    "                    print(\"\\n>> rename failed: {}\".format(src))\n",
    "                    continue\n",
    "    #remove rename_\n",
    "    for subdir, dirs, files in tqdm(os.walk(path)):\n",
    "        for i,file in enumerate(files):\n",
    "            if file.endswith(('.png')) and file.startswith(('rename_')) :\n",
    "                newfile = file.replace('rename_','')\n",
    "                src = os.path.join(subdir,file)\n",
    "                dst = os.path.join(subdir,newfile)\n",
    "                try:\n",
    "                    os.rename(src,dst)\n",
    "                except:\n",
    "                    print(\"\\n>> remove rename failed: {}\".format(src))\n",
    "                    continue               \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path=outdir+'rawframes'\n",
    "#rename_filepaths_from_dir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE FILELISTS\n",
    "def generate_filelist(videolist, filename, outdir):\n",
    "    #save imglist :mola_{train,val}_rawframes.txt\n",
    "    with open(outdir + filename, 'w') as f:\n",
    "        f.writelines(videolist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RECHECK FILELISTS\n",
    "def recheck_rawframes_filelist(rdir, totalfilelistname):\n",
    "    with open(os.path.join(rdir, totalfilelistname)) as file: totalfilelist=file.readlines()\n",
    "    #print(len(totalfilelist))\n",
    "    original=copy.copy(totalfilelist)\n",
    "    framesdir=os.path.join(rdir,'rawframes')\n",
    "    for subdir, dirs, files in tqdm(os.walk(framesdir)):\n",
    "        if files and files[0].endswith(('.png')):\n",
    "            dirname=os.path.split(subdir)[-1]\n",
    "            indices = [i for i, s in enumerate(totalfilelist) if dirname in s]\n",
    "            #print(indices)\n",
    "            for idx in indices:\n",
    "                line=totalfilelist[idx].split(' ')\n",
    "                line[-2]= str(len(files)) #update total_frames: f'{category}/{video_new_fn} {total_frames} {label}\\n' \n",
    "                totalfilelist[idx]= ' '.join(line)\n",
    "                #print(totalfilelist[idx])\n",
    "    newfilename=os.path.join(rdir, \"recheck_\"+totalfilelistname)\n",
    "    with open(newfilename, 'w') as f:\n",
    "        f.writelines(totalfilelist)  \n",
    "    comparision=[original[i]==totalfilelist[i] for i,n in enumerate(original)]\n",
    "    return comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rdir=outdir\n",
    "#totalfilelistname=filename\n",
    "#comparision=recheck_rawframes_filelist(rdir, totalfilelistname) \n",
    "\n",
    "#display(sum([not c for c in comparision]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLIT FILELIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_filelist(path):\n",
    "    filelist=[]\n",
    "    with open(path) as f:\n",
    "        filelist=f.readlines()\n",
    "    split=['train','val','test']\n",
    "    for s in split:\n",
    "        ps=[]\n",
    "        if s==\"train\": ps=['P'+str(i+1)+'_' for i in range(8)]\n",
    "        if s==\"val\": ps=['P'+str(i+1)+'_' for i in range(8,12)]\n",
    "        if s==\"test\": ps=['P'+str(i+1)+'_' for i in range(12,16)]\n",
    "        filelist_split=[l for l in filelist for p in ps if l.find(p)>-1]\n",
    "        filelist_split=list(dict.fromkeys(filelist_split))\n",
    "        fn_split=Path(path).stem.split('_')\n",
    "        fn_split[-2]=s\n",
    "        fn_split='_'.join(fn_split)\n",
    "        \n",
    "        with open(os.path.join(os.path.dirname(path),fn_split+'.txt'), 'w') as f:\n",
    "            f.writelines(filelist_split)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_filelist(outdir+\"recheck_\"+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFIG MMACTION2\n",
    "1. Option (RECOMMENDED): create a customconfig.py file \n",
    "2. Option: modify other config and train from script (see folder MMACTION2/TESTS/mmaction2_tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTI CASE STUDY (For loop script for each json Dataset - extract multiple datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mola_json(dataset=\"mola\", datasets_root_dir=None, json_dir='../mola/annotations/', outdir='out/', \n",
    "                      copy_images=True, copy_videos=False, img_number=None, level=2, dataset_type='rawframes'):\n",
    "    # Convert motionLab JSON file into  labels --------------------------------\n",
    "    jsons = glob.glob(json_dir + '*.json')\n",
    "    outdir_original = outdir\n",
    "    # Import multiple jsons\n",
    "    for json_file in sorted(jsons):\n",
    "        jsname=os.path.basename(json_file).split(\".\")[0]\n",
    "        outdir=os.path.join(outdir_original, jsname)+\"/\"\n",
    "        print(\"\\n>>>\", jsname, outdir)\n",
    "        imglist, videolist, saved_img_l, saved_video_l = mola2mmaction2(datasets_root_dir=datasets_root_dir, \n",
    "                                                                        json_file=json_file, \n",
    "                                                                        outdir=outdir, \n",
    "                                                                        copy_images=copy_images, \n",
    "                                                                        copy_videos=copy_videos, \n",
    "                                                                        img_number=img_number,\n",
    "                                                                        level=level\n",
    "                                                                       )\n",
    "        \n",
    "        if dataset_type=='rawframes':\n",
    "            # RENAME FRAMES FILEPATHS   (OBLIGATORY: mmaction2 can have errors if the total frame number is not equal to the number on filename or there are jumps in numbering)\n",
    "            print(\"\\n>>RENAMING IMAGES FRAMES...\")\n",
    "            rename_filepaths_from_dir(os.path.join(outdir, 'rawframes'))\n",
    "            # GENERATE FILELISTS\n",
    "            print(\"\\n>>GENERATE FILELIST...\")\n",
    "            filename=f'{dataset}_total_{dataset_type}.txt'\n",
    "            generate_filelist(videolist, filename, outdir)\n",
    "            # RECHECK and RENAME FILELIST (With rename normally this is just a confirmation step)\n",
    "            print(\"\\n>>RECHECK FILELIST...\")\n",
    "            time.sleep(5)\n",
    "            comparision=recheck_rawframes_filelist(outdir, filename)\n",
    "            display(sum([not c for c in comparision]))\n",
    "            # SPLIT FILELIST\n",
    "            time.sleep(5)\n",
    "            split_filelist(os.path.join(outdir,'recheck_'+filename))\n",
    "        if dataset_type=='videos':\n",
    "            pass #TODO\n",
    "        \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> opticalflow_violent /home/user/Desktop/NC/DATASETS/mma2/opticalflow_violent/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotations /mnt/Data-Ext/Datasets/Internal Datasets/"
     ]
    }
   ],
   "source": [
    "#WARNING use / in dir path if forlder\n",
    "datasets_root_dir=\"/mnt/Data-Ext/Datasets/Internal Datasets/EASYRIDE/P19/\"\n",
    "json_dir=datasets_root_dir+\"JSONS/INCAR/violent_2c_toC20/select/\"\n",
    "outdir='/home/user/Desktop/NC/DATASETS/mma2/' #don't forget the last\n",
    "dataset=\"INCAR2c\"\n",
    "dataset_type='rawframes'\n",
    "img_number=None\n",
    "copy_images=True\n",
    "copy_videos=False\n",
    "level=2\n",
    "convert_mola_json(dataset=dataset, datasets_root_dir=datasets_root_dir, json_dir=json_dir, outdir=outdir, \n",
    "                  img_number=img_number, copy_images=copy_images, copy_videos=copy_videos, level=level, \n",
    "                  dataset_type=dataset_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/Data-Ext/Datasets/Internal Datasets/EASYRIDE/P19/JSONS/INCAR/violent_2c_toC20/select/opticalflow_violent.json\n",
      "{'name': 'INCAR/20210422/Sessipn1/C10_P7_P8_1/INCAR_20210422_Sessipn1_C10_P7_P8_1_rgb.mp4', 'id': 1, 'width': 2048, 'height': 1536, 'sensor': 'rgb', 'fps': 30, 'total_frames': 580, 'dataset': 1}\n",
      "{'name': 'INCAR/20210422/Sessipn1/C10_P7_P8_1/INCAR_20210422_Sessipn1_C10_P7_P8_1_rgb.mp4', 'id': 1, 'width': 2048, 'height': 1536, 'sensor': 'rgb', 'fps': 30, 'total_frames': 580, 'dataset': 1}\n",
      "{'name': 'INCAR/20210422/Sessipn1/C10_P7_P8_1/INCAR_20210422_Sessipn1_C10_P7_P8_1_rgb.mp4', 'id': 1, 'width': 2048, 'height': 1536, 'sensor': 'rgb', 'fps': 30, 'total_frames': 580, 'dataset': 1}\n"
     ]
    }
   ],
   "source": [
    "jsons = glob.glob(json_dir + '*.json')\n",
    "json_file=jsons[0]\n",
    "print(json_file)\n",
    "with open(json_file) as f:\n",
    "    data = json.load(f)\n",
    "print(data['videos'][0])\n",
    "# create video dict {id: video}\n",
    "videos = {'%g' % x['id']: x for x in data['videos']}\n",
    "print(videos['1'])\n",
    "js=json.load(open(json_file))\n",
    "print(js['videos'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTHER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replace_from_annotation(outdir_img, json_file, data, images, videos, categories, videos_ann, level):\n",
    "    img_l=[]\n",
    "    for x in tqdm(data['annotations'], desc='Annotations %s' % json_file):  \n",
    "        # extract label and category\n",
    "        catid = '%g' % x['category_id']\n",
    "        label = catid\n",
    "        category = categories[label]['name']\n",
    "        # extract image info from x['image_id']\n",
    "        image_id='%g' % x['image_id']\n",
    "        if image_id in img_l: continue # continue to next loop if repeated image_id \n",
    "        img_l.append(image_id)\n",
    "        img = images[image_id]\n",
    "        h, w, imgf = img['height'], img['width'], img['file_name']\n",
    "        _, img_ext = os.path.splitext(imgf)\n",
    "        img_fn = Path(imgf).stem\n",
    "        # extract video info from img['video_id']\n",
    "        video_id = '%g' % img[\"video_id\"]\n",
    "        video = videos[video_id]\n",
    "        videof= video[\"name\"]\n",
    "        video_fn = Path(videof).stem\n",
    "        video_new_fn = video_fn #\"video_\"+video_id\n",
    "        video_ann= videos_ann[video_id+'_'+catid]\n",
    "        video_start_frame=video_ann[\"frame_start\"]-1 # zero if starts in  1\n",
    "        # src, dst\n",
    "        img_old_fn = \"img_\"+img_fn.zfill(5) #\"img_\"+image_id\n",
    "        img_frame=str(int(img_fn)-int(video_start_frame))\n",
    "        img_new_fn = \"img_\"+img_frame.zfill(5) #img_framenumber (imgid with zeros 00001: image_frame.zfill(5) ) Problem is I don't no the maximum of images\n",
    "        dirpath=os.path.join(outdir_img, video_new_fn)\n",
    "        if level==2: dirpath = os.path.join(outdir_img, category, video_new_fn)\n",
    "        src = os.path.join(dirpath, img_old_fn + img_ext)\n",
    "        dst = os.path.join(dirpath, img_new_fn + img_ext)\n",
    "        if src==dst: continue\n",
    "        try:\n",
    "            os.rename(src,dst)\n",
    "        except:\n",
    "            print(\"\\n>> rename failed: {}\".format(src))\n",
    "            continue\n",
    "    return\n",
    "json_file='/home/administrator/server_data_ext/Recordings/EASYRIDE/P19/INCAR/push_mola.json'\n",
    "outdir_img='/home/administrator/Z/Algorithms/mmaction2/data/INCAR/rawframes/'\n",
    "level=2\n",
    "with open(json_file) as f:\n",
    "    data = json.load(f)\n",
    "# create image dict {id: image}\n",
    "images = {'%g' % x['id']: x for x in data['images']}\n",
    "# create video dict {id: video}\n",
    "videos = {'%g' % x['id']: x for x in data['videos']}\n",
    "# create category dict {id: category}\n",
    "categories = {'%g' % x['id']: x for x in data['categories']}\n",
    "# create video ann dict {video_id_category_id: video_annotations}\n",
    "videos_ann = {'%g' % x['video_id']+'_'+'%g' % x['category_id']: x for x in data['video_annotations']}\n",
    "\n",
    "\n",
    "replace_from_annotation(outdir_img, json_file, data, images, videos, categories, videos_ann, level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAILED CODE IDEAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING TO hard to implement when you want to write images\n",
    "#TO ADD IMGID you need to search for imgid on video\n",
    "def write_from_video_annotation(data, images, videos, categories, copy_images, copy_videos, outdir_img, outdir_video):\n",
    "    # WRITE FILES (COPY & GENERATE FILELIST)\n",
    "    # video lists\n",
    "    video_l = []\n",
    "    saved_video_l= []\n",
    "    videolist = []\n",
    "    # write files \n",
    "    method=\"for\" #TODO: parfor method\n",
    "    start=time.time()\n",
    "    if method==\"for\":\n",
    "        #WRITE IMAGES\n",
    "        for x in tqdm(data['video_annotations'], desc='Video Annotations %s' % json_file):  \n",
    "            # extract video info from img['video_id']\n",
    "            video_id = '%g' % x[\"video_id\"]\n",
    "            video = videos[video_id]\n",
    "            videof= video[\"name\"]\n",
    "            video_sensor=video[\"sensor\"]\n",
    "            video_fn = Path(videof).stem\n",
    "            video_new_fn = \"video_\"+video_id\n",
    "            # extract label and category\n",
    "            catid = '%g' % x['category_id']\n",
    "            label = catid\n",
    "            category = categories[catid]\n",
    "            # extract total label frames\n",
    "            total_frames = '%g' % x['label_frames']\n",
    "            # extract category\n",
    "            category = categories[label]['name']\n",
    "            frame_start = x['frame_start'] #first frame\n",
    "            frame_end = x['frame_end'] #end frame\n",
    "            # extract image info from x['image_id']\n",
    "            imgdir=os.path.dirname(videof)+'/'+video_sensor+'/'\n",
    "            img_l= sorted( filter( os.path.isfile, glob.glob(imgdir + '*') ) )\n",
    "            # write images - 1st because if copy_images fails the rest should not be done\n",
    "            # image lists\n",
    "            img_l = []\n",
    "            saved_img_l= []\n",
    "            imglist = []\n",
    "            img_counter = 0 # image counter\n",
    "            for imgd in img_l:\n",
    "                src = os.path.join(imgd)\n",
    "                dst = os.path.join(outdir_img, video_new_fn, img_new_fn + img_ext) #TODO: how to add imgid you need to search \n",
    "                if level==2: dst = os.path.join(outdir_img, category, video_new_fn, img_new_fn + img_ext)\n",
    "                ext=extract_file(src,dst,copy=copy_images)\n",
    "                if not ext: continue #if image missing from dataset when extracting images dont write nothing more\n",
    "                # rawframe annotation file list: json to txt [ frame_directory total_frames label  ]\n",
    "                imgline = f'{video_new_fn} {total_frames} {label}\\n' # f'{video_new_fn}/{img_new_fn} {total_frames} {label}\\n'\n",
    "                if level==2: imgline = f'{category}/{video_new_fn} {total_frames} {label}\\n' # f'{category}/{video_new_fn}/{img_new_fn} {total_frames} {label}\\n'\n",
    "                imglist.append(imgline)\n",
    "                img_counter += 1\n",
    "        #remove duplicate paths\n",
    "        imglist=list(dict.fromkeys(imglist)) \n",
    "    stop = time.time()\n",
    "    elapsed=stop-start\n",
    "    print(\"time elapsed:\", elapsed)\n",
    "    return imglist, videolist, saved_img_l, saved_video_l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
